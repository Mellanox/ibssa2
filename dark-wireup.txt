
"Dark" wire up for SSA service

Assumptions:

	1) although this protocol is designed to wire up a cluster from cold
	   boot it is probably more efficient for the SSA nodes to be booted
	   prior to the compute nodes (ibacm nodes) booting.  The SM and SSA's
	   can then have a logical tree amongst themselves prior to the ibacm
	   nodes coming online.

	2) nodes can come and go.  All wire up is done in a dynamic fashion for
	   both ibacm and SSA nodes.




SSA's can join mcast group for heartbeat communications.  This should scale as
there were be relatively few of them.  When they come online they send messages
to the SM/Master SSA that they exist.

The Master SSA will determine where in the physical and logical topology the
SSA's should be located.



Multicast vs SR for initial wire up.


Use SR to find initial join to tree.

Once joined we get 2 parents.  (Primary and backup)

After this the client does not need to do a "dark query" for the tree, unless
the primary _and_ backup fail.








Push info up and down tree.  Similar data connection???

Data for up tree (messages known for now)

	1) inform info
	2) names for resolution (IP's, hostnames)


Down is: (RDMA and messages)

	1) SA DB
	2) events
	3) Name resolution (invent new things here)


So who controls the data?

When data changes; Do we push data down or pull it down?

This could be different depending on where in the tree we are.

Data is collected by a single node and timestamps that with a single epoch...

How do we know that we have collected enough data to publish to all nodes?

What about an algorithm which controls by time or number of nodes?

Path records depend on the source not just the destination...


3 "pieces"

plugin
SSA (daemon)
	Plugin
ibacm

Within this a library package

So 4 packages (current ibacm, SSA, plugin, and common libraries)

I am on the hook to do the distribution layer.


